# entropic-scaling-laws
Reproducible study of how data predictability affects LLM scaling. Computes Shannon H0/Hk, n-gram entropy, and gzip/zstd BPB to bucket text. Runs controlled nanoGPT sweeps. Reports bits/byte + MDL-style adjusted code length.
