# entropic-scaling-laws
Reproducible study of how data predictability affects LLM scaling. Computes Shannon H0/Hk, n-gram entropy, and gzip/zstd BPB to bucket text; runs controlled nanoGPT sweeps; reports bits/byte + MDL-style adjusted code length.
